{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "header"
   },
   "source": [
    "# Chapter 13: Pipelines, Cross-Validation, and Tuning\n",
    "## Practice Activities\n",
    "\n",
    "This notebook contains all practice activities from Chapter 13 of \"Data Science and Machine Learning with Python.\"\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "setup"
   },
   "source": [
    "## ðŸ“¦ Setup: Import Libraries\n",
    "\n",
    "First, let's import all the necessary libraries."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "imports"
   },
   "outputs": [],
   "source": [
    "# Data manipulation\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "# Scikit-learn components\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.preprocessing import StandardScaler, OneHotEncoder, PolynomialFeatures\n",
    "from sklearn.compose import ColumnTransformer\n",
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.model_selection import train_test_split, cross_val_score, GridSearchCV\n",
    "from sklearn.metrics import r2_score, mean_squared_error\n",
    "\n",
    "# Visualization\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "# Settings\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "pd.set_option('display.max_columns', None)\n",
    "pd.set_option('display.width', None)\n",
    "\n",
    "print(\"âœ“ All libraries imported successfully!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "load_data"
   },
   "source": [
    "## ðŸ“Š Load the AMES Housing Dataset\n",
    "\n",
    "Load the AMES Housing dataset. Make sure you've uploaded the file to your Colab environment.\n",
    "\n",
    "**If you haven't uploaded the file yet:**\n",
    "1. Click the folder icon on the left sidebar\n",
    "2. Click the upload button\n",
    "3. Select your `AmesHousing.csv` file\n",
    "\n",
    "**Alternative:** You can also download it directly from the course repository."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "load"
   },
   "outputs": [],
   "source": [
    "# Load the dataset\n",
    "# If the file is in your current directory:\n",
    "ames = pd.read_csv(\"AmesHousing.csv\")\n",
    "\n",
    "# If you uploaded to a specific path, modify the path accordingly:\n",
    "# ames = pd.read_csv(\"/content/AmesHousing.csv\")\n",
    "\n",
    "print(f\"Dataset loaded successfully!\")\n",
    "print(f\"Shape: {ames.shape}\")\n",
    "print(f\"\\nFirst few rows:\")\n",
    "ames.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "explore"
   },
   "source": [
    "### Quick Data Exploration"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "explore_code"
   },
   "outputs": [],
   "source": [
    "# Check the columns we'll be using\n",
    "print(\"Columns we'll use in our analysis:\")\n",
    "print(\"- Gr Liv Area: Above grade (ground) living area square feet\")\n",
    "print(\"- TotRms AbvGrd: Total rooms above grade (does not include bathrooms)\")\n",
    "print(\"- Bldg Type: Type of dwelling\")\n",
    "print(\"- SalePrice: Sale price (target variable)\")\n",
    "print(\"\\nBasic statistics:\")\n",
    "ames[['Gr Liv Area', 'TotRms AbvGrd', 'Bldg Type', 'SalePrice']].describe()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "prepare"
   },
   "source": [
    "## ðŸŽ¯ Prepare Data for Modeling\n",
    "\n",
    "**IMPORTANT:** We will perform the train-test split **ONLY ONCE** at the beginning. All models will use the same train and test sets."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "prepare_code"
   },
   "outputs": [],
   "source": [
    "# Drop rows with missing values in the columns we need\n",
    "ames_clean = ames.dropna(subset=['Gr Liv Area', 'TotRms AbvGrd', 'Bldg Type', 'SalePrice'])\n",
    "\n",
    "# Separate features and target\n",
    "X = ames_clean[['Gr Liv Area', 'TotRms AbvGrd', 'Bldg Type']]\n",
    "y = ames_clean['SalePrice']\n",
    "\n",
    "# Perform train-test split ONCE (as instructed in the chapter)\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3, random_state=42)\n",
    "\n",
    "print(\"âœ“ Data prepared successfully!\")\n",
    "print(f\"Training set size: {len(X_train)}\")\n",
    "print(f\"Test set size: {len(X_test)}\")\n",
    "print(f\"\\nFeatures: {list(X.columns)}\")\n",
    "print(f\"Target: SalePrice\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "activity1_header"
   },
   "source": [
    "---\n",
    "\n",
    "# ðŸ“ Practice Activity 1: Four Models with Test Set Evaluation\n",
    "\n",
    "**Task (Section 13.2.5):** Consider four possible models for predicting house prices:\n",
    "\n",
    "1. Using only the size and number of rooms\n",
    "2. Using size, number of rooms, and building type\n",
    "3. Using size and building type, and their interaction\n",
    "4. Using a 5-degree polynomial on size, a 5-degree polynomial on number of rooms, and building type\n",
    "\n",
    "Set up a pipeline for each of these four models. Then, get predictions on the test set for each of your pipelines, and compute the root mean squared error. Which model performed best?\n",
    "\n",
    "**Note:** You should only use the function `train_test_split()` one time in your code; that is, we should be predicting on the **same** test set for all three models."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "model1"
   },
   "source": [
    "## Model 1: Size and Number of Rooms Only"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "model1_code"
   },
   "outputs": [],
   "source": [
    "# Model 1: Simple model with just size and number of rooms\n",
    "pipeline_1 = Pipeline([\n",
    "    (\"standardize\", StandardScaler()),\n",
    "    (\"linear_regression\", LinearRegression())\n",
    "])\n",
    "\n",
    "# Select only the numeric features\n",
    "X_train_1 = X_train[['Gr Liv Area', 'TotRms AbvGrd']]\n",
    "X_test_1 = X_test[['Gr Liv Area', 'TotRms AbvGrd']]\n",
    "\n",
    "# Fit the pipeline\n",
    "pipeline_1.fit(X_train_1, y_train)\n",
    "\n",
    "# Make predictions\n",
    "y_pred_1 = pipeline_1.predict(X_test_1)\n",
    "\n",
    "# Calculate metrics\n",
    "rmse_1 = np.sqrt(mean_squared_error(y_test, y_pred_1))\n",
    "r2_1 = r2_score(y_test, y_pred_1)\n",
    "\n",
    "print(\"Model 1: Size and Number of Rooms Only\")\n",
    "print(\"=\" * 50)\n",
    "print(f\"Test RMSE: ${rmse_1:,.2f}\")\n",
    "print(f\"Test RÂ²: {r2_1:.4f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "model2"
   },
   "source": [
    "## Model 2: Size, Number of Rooms, and Building Type"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "model2_code"
   },
   "outputs": [],
   "source": [
    "# Model 2: Add building type (categorical variable)\n",
    "# We need ColumnTransformer to handle both numeric and categorical features\n",
    "\n",
    "ct_2 = ColumnTransformer([\n",
    "    (\"dummify\", OneHotEncoder(sparse_output=False), [\"Bldg Type\"]),\n",
    "    (\"standardize\", StandardScaler(), [\"Gr Liv Area\", \"TotRms AbvGrd\"])\n",
    "],\n",
    "remainder=\"drop\"\n",
    ")\n",
    "\n",
    "pipeline_2 = Pipeline([\n",
    "    (\"preprocessing\", ct_2),\n",
    "    (\"linear_regression\", LinearRegression())\n",
    "]).set_output(transform=\"pandas\")\n",
    "\n",
    "# Fit the pipeline\n",
    "pipeline_2.fit(X_train, y_train)\n",
    "\n",
    "# Make predictions\n",
    "y_pred_2 = pipeline_2.predict(X_test)\n",
    "\n",
    "# Calculate metrics\n",
    "rmse_2 = np.sqrt(mean_squared_error(y_test, y_pred_2))\n",
    "r2_2 = r2_score(y_test, y_pred_2)\n",
    "\n",
    "print(\"Model 2: Size, Number of Rooms, and Building Type\")\n",
    "print(\"=\" * 50)\n",
    "print(f\"Test RMSE: ${rmse_2:,.2f}\")\n",
    "print(f\"Test RÂ²: {r2_2:.4f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "model3"
   },
   "source": [
    "## Model 3: Size, Building Type, and Their Interaction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "model3_code"
   },
   "outputs": [],
   "source": [
    "# Model 3: Include interaction between size and building type\n",
    "\n",
    "ct_3 = ColumnTransformer([\n",
    "    (\"dummify\", OneHotEncoder(sparse_output=False), [\"Bldg Type\"]),\n",
    "    (\"standardize\", StandardScaler(), [\"Gr Liv Area\"])\n",
    "],\n",
    "remainder=\"drop\"\n",
    ")\n",
    "\n",
    "pipeline_3 = Pipeline([\n",
    "    (\"preprocessing\", ct_3),\n",
    "    (\"interaction\", PolynomialFeatures(interaction_only=True)),\n",
    "    (\"linear_regression\", LinearRegression())\n",
    "]).set_output(transform=\"pandas\")\n",
    "\n",
    "# Select only the features we need for this model\n",
    "X_train_3 = X_train[['Gr Liv Area', 'Bldg Type']]\n",
    "X_test_3 = X_test[['Gr Liv Area', 'Bldg Type']]\n",
    "\n",
    "# Fit the pipeline\n",
    "pipeline_3.fit(X_train_3, y_train)\n",
    "\n",
    "# Make predictions\n",
    "y_pred_3 = pipeline_3.predict(X_test_3)\n",
    "\n",
    "# Calculate metrics\n",
    "rmse_3 = np.sqrt(mean_squared_error(y_test, y_pred_3))\n",
    "r2_3 = r2_score(y_test, y_pred_3)\n",
    "\n",
    "print(\"Model 3: Size, Building Type, and Their Interaction\")\n",
    "print(\"=\" * 50)\n",
    "print(f\"Test RMSE: ${rmse_3:,.2f}\")\n",
    "print(f\"Test RÂ²: {r2_3:.4f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "model4"
   },
   "source": [
    "## Model 4: 5-Degree Polynomials on Size and Rooms, Plus Building Type"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "model4_code"
   },
   "outputs": [],
   "source": [
    "# Model 4: Complex model with polynomial features\n",
    "\n",
    "ct_4 = ColumnTransformer([\n",
    "    (\"dummify\", OneHotEncoder(sparse_output=False), [\"Bldg Type\"]),\n",
    "    (\"polynomial_size\", PolynomialFeatures(degree=5), [\"Gr Liv Area\"]),\n",
    "    (\"polynomial_rooms\", PolynomialFeatures(degree=5), [\"TotRms AbvGrd\"])\n",
    "],\n",
    "remainder=\"drop\"\n",
    ")\n",
    "\n",
    "pipeline_4 = Pipeline([\n",
    "    (\"preprocessing\", ct_4),\n",
    "    (\"linear_regression\", LinearRegression())\n",
    "]).set_output(transform=\"pandas\")\n",
    "\n",
    "# Fit the pipeline\n",
    "pipeline_4.fit(X_train, y_train)\n",
    "\n",
    "# Make predictions\n",
    "y_pred_4 = pipeline_4.predict(X_test)\n",
    "\n",
    "# Calculate metrics\n",
    "rmse_4 = np.sqrt(mean_squared_error(y_test, y_pred_4))\n",
    "r2_4 = r2_score(y_test, y_pred_4)\n",
    "\n",
    "print(\"Model 4: 5-Degree Polynomials on Size and Rooms, Plus Building Type\")\n",
    "print(\"=\" * 50)\n",
    "print(f\"Test RMSE: ${rmse_4:,.2f}\")\n",
    "print(f\"Test RÂ²: {r2_4:.4f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "activity1_summary"
   },
   "source": [
    "## ðŸ“Š Summary: Practice Activity 1 Results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "activity1_summary_code"
   },
   "outputs": [],
   "source": [
    "# Create a summary dataframe\n",
    "results_df = pd.DataFrame({\n",
    "    'Model': [\n",
    "        'Model 1: Size + Rooms',\n",
    "        'Model 2: Size + Rooms + Bldg Type',\n",
    "        'Model 3: Size Ã— Bldg Type Interaction',\n",
    "        'Model 4: 5-Degree Polynomials'\n",
    "    ],\n",
    "    'Test RMSE': [rmse_1, rmse_2, rmse_3, rmse_4],\n",
    "    'Test RÂ²': [r2_1, r2_2, r2_3, r2_4]\n",
    "})\n",
    "\n",
    "# Sort by RMSE (lower is better)\n",
    "results_df = results_df.sort_values('Test RMSE')\n",
    "\n",
    "print(\"\\n\" + \"=\" * 70)\n",
    "print(\"PRACTICE ACTIVITY 1 SUMMARY: Test Set Performance\")\n",
    "print(\"=\" * 70)\n",
    "print(results_df.to_string(index=False))\n",
    "print(\"\\n\" + \"=\" * 70)\n",
    "print(f\"âœ“ Best Model: {results_df.iloc[0]['Model']}\")\n",
    "print(f\"  RMSE: ${results_df.iloc[0]['Test RMSE']:,.2f}\")\n",
    "print(f\"  RÂ²: {results_df.iloc[0]['Test RÂ²']:.4f}\")\n",
    "print(\"=\" * 70)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "activity1_viz"
   },
   "source": [
    "## ðŸ“ˆ Visualization: Model Comparison"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "activity1_viz_code"
   },
   "outputs": [],
   "source": [
    "# Create visualization\n",
    "fig, axes = plt.subplots(1, 2, figsize=(14, 5))\n",
    "\n",
    "# Plot 1: RMSE comparison\n",
    "colors = ['#2ecc71' if i == 0 else '#3498db' for i in range(len(results_df))]\n",
    "axes[0].barh(results_df['Model'], results_df['Test RMSE'], color=colors)\n",
    "axes[0].set_xlabel('RMSE ($)', fontsize=12)\n",
    "axes[0].set_title('Test Set RMSE by Model\\n(Lower is Better)', fontsize=14, fontweight='bold')\n",
    "axes[0].invert_yaxis()\n",
    "\n",
    "# Plot 2: RÂ² comparison\n",
    "axes[1].barh(results_df['Model'], results_df['Test RÂ²'], color=colors)\n",
    "axes[1].set_xlabel('RÂ² Score', fontsize=12)\n",
    "axes[1].set_title('Test Set RÂ² by Model\\n(Higher is Better)', fontsize=14, fontweight='bold')\n",
    "axes[1].invert_yaxis()\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "activity2_header"
   },
   "source": [
    "---\n",
    "\n",
    "# ðŸ“ Practice Activity 2: Cross-Validation on Four Models\n",
    "\n",
    "**Task (Section 13.3.1):** Once again consider four modeling options for house price:\n",
    "\n",
    "1. Using only the size and number of rooms\n",
    "2. Using size, number of rooms, and building type\n",
    "3. Using size and building type, and their interaction\n",
    "4. Using a 5-degree polynomial on size, a 5-degree polynomial on number of rooms, and building type\n",
    "\n",
    "Use `cross_val_score()` with the pipelines you made earlier to find the cross-validated root mean squared error for each model.\n",
    "\n",
    "**Which do you prefer? Does this agree with your conclusion from earlier?**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "cv_model1"
   },
   "source": [
    "## Model 1: Cross-Validation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "cv_model1_code"
   },
   "outputs": [],
   "source": [
    "# Model 1 with cross-validation\n",
    "print(\"Model 1: Size and Number of Rooms Only\")\n",
    "print(\"=\" * 50)\n",
    "\n",
    "# Get RÂ² scores across 5 folds\n",
    "cv_scores_1 = cross_val_score(\n",
    "    pipeline_1, \n",
    "    X[['Gr Liv Area', 'TotRms AbvGrd']], \n",
    "    y, \n",
    "    cv=5, \n",
    "    scoring='r2'\n",
    ")\n",
    "\n",
    "# Get RMSE (note: sklearn returns negative MSE, so we negate and take sqrt)\n",
    "cv_mse_scores_1 = -cross_val_score(\n",
    "    pipeline_1, \n",
    "    X[['Gr Liv Area', 'TotRms AbvGrd']], \n",
    "    y, \n",
    "    cv=5, \n",
    "    scoring='neg_mean_squared_error'\n",
    ")\n",
    "cv_rmse_1 = np.sqrt(cv_mse_scores_1.mean())\n",
    "cv_r2_1 = cv_scores_1.mean()\n",
    "\n",
    "print(f\"Cross-Validated RMSE: ${cv_rmse_1:,.2f}\")\n",
    "print(f\"Cross-Validated RÂ²: {cv_r2_1:.4f}\")\n",
    "print(f\"RÂ² scores across 5 folds: {cv_scores_1}\")\n",
    "print(f\"Standard deviation of RÂ²: {cv_scores_1.std():.4f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "cv_model2"
   },
   "source": [
    "## Model 2: Cross-Validation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "cv_model2_code"
   },
   "outputs": [],
   "source": [
    "# Model 2 with cross-validation\n",
    "print(\"Model 2: Size, Number of Rooms, and Building Type\")\n",
    "print(\"=\" * 50)\n",
    "\n",
    "cv_scores_2 = cross_val_score(pipeline_2, X, y, cv=5, scoring='r2')\n",
    "cv_mse_scores_2 = -cross_val_score(pipeline_2, X, y, cv=5, scoring='neg_mean_squared_error')\n",
    "cv_rmse_2 = np.sqrt(cv_mse_scores_2.mean())\n",
    "cv_r2_2 = cv_scores_2.mean()\n",
    "\n",
    "print(f\"Cross-Validated RMSE: ${cv_rmse_2:,.2f}\")\n",
    "print(f\"Cross-Validated RÂ²: {cv_r2_2:.4f}\")\n",
    "print(f\"RÂ² scores across 5 folds: {cv_scores_2}\")\n",
    "print(f\"Standard deviation of RÂ²: {cv_scores_2.std():.4f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "cv_model3"
   },
   "source": [
    "## Model 3: Cross-Validation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "cv_model3_code"
   },
   "outputs": [],
   "source": [
    "# Model 3 with cross-validation\n",
    "print(\"Model 3: Size, Building Type, and Their Interaction\")\n",
    "print(\"=\" * 50)\n",
    "\n",
    "cv_scores_3 = cross_val_score(\n",
    "    pipeline_3, \n",
    "    X[['Gr Liv Area', 'Bldg Type']], \n",
    "    y, \n",
    "    cv=5, \n",
    "    scoring='r2'\n",
    ")\n",
    "cv_mse_scores_3 = -cross_val_score(\n",
    "    pipeline_3, \n",
    "    X[['Gr Liv Area', 'Bldg Type']], \n",
    "    y, \n",
    "    cv=5, \n",
    "    scoring='neg_mean_squared_error'\n",
    ")\n",
    "cv_rmse_3 = np.sqrt(cv_mse_scores_3.mean())\n",
    "cv_r2_3 = cv_scores_3.mean()\n",
    "\n",
    "print(f\"Cross-Validated RMSE: ${cv_rmse_3:,.2f}\")\n",
    "print(f\"Cross-Validated RÂ²: {cv_r2_3:.4f}\")\n",
    "print(f\"RÂ² scores across 5 folds: {cv_scores_3}\")\n",
    "print(f\"Standard deviation of RÂ²: {cv_scores_3.std():.4f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "cv_model4"
   },
   "source": [
    "## Model 4: Cross-Validation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "cv_model4_code"
   },
   "outputs": [],
   "source": [
    "# Model 4 with cross-validation\n",
    "print(\"Model 4: 5-Degree Polynomials on Size and Rooms, Plus Building Type\")\n",
    "print(\"=\" * 50)\n",
    "\n",
    "cv_scores_4 = cross_val_score(pipeline_4, X, y, cv=5, scoring='r2')\n",
    "cv_mse_scores_4 = -cross_val_score(pipeline_4, X, y, cv=5, scoring='neg_mean_squared_error')\n",
    "cv_rmse_4 = np.sqrt(cv_mse_scores_4.mean())\n",
    "cv_r2_4 = cv_scores_4.mean()\n",
    "\n",
    "print(f\"Cross-Validated RMSE: ${cv_rmse_4:,.2f}\")\n",
    "print(f\"Cross-Validated RÂ²: {cv_r2_4:.4f}\")\n",
    "print(f\"RÂ² scores across 5 folds: {cv_scores_4}\")\n",
    "print(f\"Standard deviation of RÂ²: {cv_scores_4.std():.4f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "activity2_summary"
   },
   "source": [
    "## ðŸ“Š Summary: Practice Activity 2 Results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "activity2_summary_code"
   },
   "outputs": [],
   "source": [
    "# Create summary dataframe for cross-validation results\n",
    "cv_results_df = pd.DataFrame({\n",
    "    'Model': [\n",
    "        'Model 1: Size + Rooms',\n",
    "        'Model 2: Size + Rooms + Bldg Type',\n",
    "        'Model 3: Size Ã— Bldg Type Interaction',\n",
    "        'Model 4: 5-Degree Polynomials'\n",
    "    ],\n",
    "    'CV RMSE': [cv_rmse_1, cv_rmse_2, cv_rmse_3, cv_rmse_4],\n",
    "    'CV RÂ²': [cv_r2_1, cv_r2_2, cv_r2_3, cv_r2_4]\n",
    "})\n",
    "\n",
    "# Sort by RMSE (lower is better)\n",
    "cv_results_df = cv_results_df.sort_values('CV RMSE')\n",
    "\n",
    "print(\"\\n\" + \"=\" * 70)\n",
    "print(\"PRACTICE ACTIVITY 2 SUMMARY: Cross-Validation Performance\")\n",
    "print(\"=\" * 70)\n",
    "print(cv_results_df.to_string(index=False))\n",
    "print(\"\\n\" + \"=\" * 70)\n",
    "print(f\"âœ“ Best Model: {cv_results_df.iloc[0]['Model']}\")\n",
    "print(f\"  CV RMSE: ${cv_results_df.iloc[0]['CV RMSE']:,.2f}\")\n",
    "print(f\"  CV RÂ²: {cv_results_df.iloc[0]['CV RÂ²']:.4f}\")\n",
    "print(\"=\" * 70)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "comparison"
   },
   "source": [
    "## ðŸ” Comparison: Test Set vs Cross-Validation\n",
    "\n",
    "Let's compare the results from both approaches to answer the question: **Does cross-validation agree with the test set results?**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "comparison_code"
   },
   "outputs": [],
   "source": [
    "# Create comprehensive comparison\n",
    "comparison_df = pd.DataFrame({\n",
    "    'Model': [\n",
    "        'Model 1: Size + Rooms',\n",
    "        'Model 2: Size + Rooms + Bldg Type',\n",
    "        'Model 3: Size Ã— Bldg Type Interaction',\n",
    "        'Model 4: 5-Degree Polynomials'\n",
    "    ],\n",
    "    'Test RMSE': [rmse_1, rmse_2, rmse_3, rmse_4],\n",
    "    'CV RMSE': [cv_rmse_1, cv_rmse_2, cv_rmse_3, cv_rmse_4],\n",
    "    'Test RÂ²': [r2_1, r2_2, r2_3, r2_4],\n",
    "    'CV RÂ²': [cv_r2_1, cv_r2_2, cv_r2_3, cv_r2_4]\n",
    "})\n",
    "\n",
    "print(\"\\n\" + \"=\" * 85)\n",
    "print(\"COMPARISON: Test Set vs Cross-Validation\")\n",
    "print(\"=\" * 85)\n",
    "print(comparison_df.to_string(index=False))\n",
    "print(\"\\n\" + \"=\" * 85)\n",
    "\n",
    "# Determine best models\n",
    "best_test = results_df.iloc[0]['Model']\n",
    "best_cv = cv_results_df.iloc[0]['Model']\n",
    "\n",
    "print(\"\\nðŸ“Š ANALYSIS:\")\n",
    "print(f\"  Best model on test set: {best_test}\")\n",
    "print(f\"  Best model with CV: {best_cv}\")\n",
    "\n",
    "if best_test == best_cv:\n",
    "    print(\"  âœ“ Both methods AGREE on the best model!\")\n",
    "else:\n",
    "    print(\"  âš  Methods DISAGREE - Cross-validation is more reliable!\")\n",
    "    print(\"\\nðŸ’¡ KEY INSIGHT:\")\n",
    "    print(\"  Single train-test splits can be misleading due to randomness.\")\n",
    "    print(\"  Cross-validation averages over multiple splits, giving more\")\n",
    "    print(\"  stable and reliable estimates of model performance.\")\n",
    "\n",
    "print(\"=\" * 85)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "cv_viz"
   },
   "source": [
    "## ðŸ“ˆ Visualization: Test Set vs Cross-Validation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "cv_viz_code"
   },
   "outputs": [],
   "source": [
    "# Create comparison visualization\n",
    "fig, ax = plt.subplots(figsize=(12, 6))\n",
    "\n",
    "x = np.arange(len(comparison_df))\n",
    "width = 0.35\n",
    "\n",
    "bars1 = ax.bar(x - width/2, comparison_df['Test RMSE'], width, label='Test Set', alpha=0.8, color='#3498db')\n",
    "bars2 = ax.bar(x + width/2, comparison_df['CV RMSE'], width, label='Cross-Validation', alpha=0.8, color='#e74c3c')\n",
    "\n",
    "ax.set_xlabel('Model', fontsize=12)\n",
    "ax.set_ylabel('RMSE ($)', fontsize=12)\n",
    "ax.set_title('Test Set RMSE vs Cross-Validated RMSE\\n(Lower is Better)', fontsize=14, fontweight='bold')\n",
    "ax.set_xticks(x)\n",
    "ax.set_xticklabels(['Model 1', 'Model 2', 'Model 3', 'Model 4'], rotation=45, ha='right')\n",
    "ax.legend()\n",
    "ax.grid(axis='y', alpha=0.3)\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "activity3_header"
   },
   "source": [
    "---\n",
    "\n",
    "# ðŸ“ Practice Activity 3: Hyperparameter Tuning\n",
    "\n",
    "**Task (Section 13.3.3):** Consider *one hundred* modeling options for house price:\n",
    "\n",
    "1. Using only the size and number of rooms\n",
    "2. Using size, number of rooms, and building type\n",
    "3. Using size and building type, and their interaction\n",
    "4. Using a 5-degree polynomial on size, a 5-degree polynomial on number of rooms, and building type\n",
    "\n",
    "Use `cross_val_score()` with the pipelines you made earlier to find the cross-validated root mean squared error for each model.\n",
    "\n",
    "**Note:** While the chapter mentions \"one hundred\" options, we'll explore a systematic grid search across polynomial degrees to demonstrate the tuning process."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "grid_setup"
   },
   "source": [
    "## Setup: Create Pipeline for Tuning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "grid_setup_code"
   },
   "outputs": [],
   "source": [
    "# Create a pipeline with polynomial features that we can tune\n",
    "ct_tuning = ColumnTransformer([\n",
    "    (\"dummify\", OneHotEncoder(sparse_output=False), [\"Bldg Type\"]),\n",
    "    (\"polynomial\", PolynomialFeatures(), [\"Gr Liv Area\", \"TotRms AbvGrd\"])\n",
    "],\n",
    "remainder=\"drop\"\n",
    ")\n",
    "\n",
    "pipeline_tuning = Pipeline([\n",
    "    (\"preprocessing\", ct_tuning),\n",
    "    (\"linear_regression\", LinearRegression())\n",
    "]).set_output(transform=\"pandas\")\n",
    "\n",
    "print(\"âœ“ Tuning pipeline created successfully!\")\n",
    "print(\"\\nPipeline structure:\")\n",
    "print(pipeline_tuning)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "grid_search"
   },
   "source": [
    "## Perform Grid Search"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "grid_search_code"
   },
   "outputs": [],
   "source": [
    "# Define parameter grid - test polynomial degrees from 1 to 10\n",
    "param_grid = {\n",
    "    'preprocessing__polynomial__degree': np.arange(1, 11)\n",
    "}\n",
    "\n",
    "print(\"Setting up GridSearchCV...\")\n",
    "print(f\"Testing {len(param_grid['preprocessing__polynomial__degree'])} different polynomial degrees\")\n",
    "print(\"with 5-fold cross-validation.\")\n",
    "print(f\"Total number of fits: {len(param_grid['preprocessing__polynomial__degree']) * 5}\")\n",
    "print(\"\\nThis may take a moment...\")\n",
    "\n",
    "# Create and fit GridSearchCV\n",
    "gscv = GridSearchCV(\n",
    "    pipeline_tuning, \n",
    "    param_grid, \n",
    "    cv=5, \n",
    "    scoring='r2',\n",
    "    return_train_score=True,\n",
    "    verbose=1\n",
    ")\n",
    "\n",
    "gscv.fit(X, y)\n",
    "\n",
    "print(\"\\nâœ“ Grid search complete!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "grid_results"
   },
   "source": [
    "## Analyze Grid Search Results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "grid_results_code"
   },
   "outputs": [],
   "source": [
    "# Extract and display results\n",
    "cv_results = pd.DataFrame(gscv.cv_results_)\n",
    "\n",
    "results_summary = pd.DataFrame({\n",
    "    'Degree': param_grid['preprocessing__polynomial__degree'],\n",
    "    'Mean CV RÂ²': cv_results['mean_test_score'],\n",
    "    'Std CV RÂ²': cv_results['std_test_score'],\n",
    "    'Mean Train RÂ²': cv_results['mean_train_score']\n",
    "})\n",
    "\n",
    "print(\"\\n\" + \"=\" * 70)\n",
    "print(\"GRID SEARCH RESULTS: Polynomial Degree Tuning\")\n",
    "print(\"=\" * 70)\n",
    "print(results_summary.to_string(index=False))\n",
    "print(\"\\n\" + \"=\" * 70)\n",
    "print(f\"\\nâœ“ Best polynomial degree: {gscv.best_params_['preprocessing__polynomial__degree']}\")\n",
    "print(f\"  Best cross-validated RÂ²: {gscv.best_score_:.4f}\")\n",
    "print(\"=\" * 70)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "overfitting"
   },
   "source": [
    "## Check for Overfitting"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "overfitting_code"
   },
   "outputs": [],
   "source": [
    "print(\"\\n\" + \"=\" * 70)\n",
    "print(\"OVERFITTING ANALYSIS\")\n",
    "print(\"=\" * 70)\n",
    "print(\"\\nChecking the gap between training and cross-validation performance:\")\n",
    "print(\"Large gaps indicate overfitting.\\n\")\n",
    "\n",
    "for idx, row in results_summary.iterrows():\n",
    "    gap = row['Mean Train RÂ²'] - row['Mean CV RÂ²']\n",
    "    warning = \"âš  Possible overfitting\" if gap > 0.05 else \"âœ“ Good generalization\"\n",
    "    print(f\"Degree {int(row['Degree'])}: \"\n",
    "          f\"Train RÂ² = {row['Mean Train RÂ²']:.4f}, \"\n",
    "          f\"CV RÂ² = {row['Mean CV RÂ²']:.4f} \"\n",
    "          f\"(Gap: {gap:.4f}) {warning}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "grid_viz"
   },
   "source": [
    "## ðŸ“ˆ Visualization: Model Complexity vs Performance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "grid_viz_code"
   },
   "outputs": [],
   "source": [
    "# Create comprehensive visualization\n",
    "fig, axes = plt.subplots(1, 2, figsize=(15, 5))\n",
    "\n",
    "# Plot 1: RÂ² vs Polynomial Degree\n",
    "axes[0].plot(results_summary['Degree'], results_summary['Mean Train RÂ²'], \n",
    "             marker='o', label='Training RÂ²', linewidth=2, markersize=8)\n",
    "axes[0].plot(results_summary['Degree'], results_summary['Mean CV RÂ²'], \n",
    "             marker='s', label='Cross-Validation RÂ²', linewidth=2, markersize=8)\n",
    "axes[0].axvline(x=gscv.best_params_['preprocessing__polynomial__degree'], \n",
    "                color='red', linestyle='--', alpha=0.7, label='Best Degree')\n",
    "axes[0].set_xlabel('Polynomial Degree', fontsize=12)\n",
    "axes[0].set_ylabel('RÂ² Score', fontsize=12)\n",
    "axes[0].set_title('Model Performance vs Complexity\\n(Higher is Better)', \n",
    "                  fontsize=14, fontweight='bold')\n",
    "axes[0].legend()\n",
    "axes[0].grid(alpha=0.3)\n",
    "\n",
    "# Plot 2: Overfitting Gap\n",
    "gap = results_summary['Mean Train RÂ²'] - results_summary['Mean CV RÂ²']\n",
    "colors = ['#2ecc71' if g < 0.05 else '#e74c3c' for g in gap]\n",
    "axes[1].bar(results_summary['Degree'], gap, color=colors, alpha=0.7)\n",
    "axes[1].axhline(y=0.05, color='orange', linestyle='--', alpha=0.7, \n",
    "                label='Overfitting Threshold')\n",
    "axes[1].set_xlabel('Polynomial Degree', fontsize=12)\n",
    "axes[1].set_ylabel('Train RÂ² - CV RÂ² (Gap)', fontsize=12)\n",
    "axes[1].set_title('Overfitting Check\\n(Lower Gap is Better)', \n",
    "                  fontsize=14, fontweight='bold')\n",
    "axes[1].legend()\n",
    "axes[1].grid(axis='y', alpha=0.3)\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "final_summary"
   },
   "source": [
    "---\n",
    "\n",
    "# ðŸŽ¯ Final Summary and Key Takeaways"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "final_summary_code"
   },
   "outputs": [],
   "source": [
    "print(\"\\n\" + \"=\" * 80)\n",
    "print(\"FINAL SUMMARY: ALL PRACTICE ACTIVITIES\")\n",
    "print(\"=\" * 80)\n",
    "\n",
    "print(\"\\nðŸ“Š KEY FINDINGS:\")\n",
    "print(\"-\" * 80)\n",
    "\n",
    "print(f\"\\n1. Best Model on Test Set (Activity 1):\")\n",
    "print(f\"   Model: {results_df.iloc[0]['Model']}\")\n",
    "print(f\"   Test RMSE: ${results_df.iloc[0]['Test RMSE']:,.2f}\")\n",
    "print(f\"   Test RÂ²: {results_df.iloc[0]['Test RÂ²']:.4f}\")\n",
    "\n",
    "print(f\"\\n2. Best Model with Cross-Validation (Activity 2):\")\n",
    "print(f\"   Model: {cv_results_df.iloc[0]['Model']}\")\n",
    "print(f\"   CV RMSE: ${cv_results_df.iloc[0]['CV RMSE']:,.2f}\")\n",
    "print(f\"   CV RÂ²: {cv_results_df.iloc[0]['CV RÂ²']:.4f}\")\n",
    "\n",
    "print(f\"\\n3. Optimal Polynomial Degree (Activity 3):\")\n",
    "print(f\"   Best degree: {gscv.best_params_['preprocessing__polynomial__degree']}\")\n",
    "print(f\"   Best CV RÂ²: {gscv.best_score_:.4f}\")\n",
    "\n",
    "print(\"\\n\\nðŸ’¡ KEY LESSONS FROM CHAPTER 13:\")\n",
    "print(\"-\" * 80)\n",
    "print(\"\\nâœ“ Pipelines prevent data leakage\")\n",
    "print(\"  â†’ Ensure preprocessing uses only training data statistics\")\n",
    "print(\"  â†’ Automatically apply same transformations to test data\")\n",
    "\n",
    "print(\"\\nâœ“ Cross-validation is more reliable than single train-test splits\")\n",
    "print(\"  â†’ Averages over multiple splits for stable estimates\")\n",
    "print(\"  â†’ Helps detect when we're getting 'lucky' with one split\")\n",
    "\n",
    "print(\"\\nâœ“ Simpler models often generalize better\")\n",
    "print(\"  â†’ Complex models (high-degree polynomials) can overfit\")\n",
    "print(\"  â†’ Adding features doesn't always improve performance\")\n",
    "\n",
    "print(\"\\nâœ“ Systematic hyperparameter tuning is essential\")\n",
    "print(\"  â†’ GridSearchCV automates the cross-validation process\")\n",
    "print(\"  â†’ Helps find optimal model configuration\")\n",
    "\n",
    "print(\"\\n\" + \"=\" * 80)\n",
    "print(\"PRACTICE ACTIVITIES COMPLETE! ðŸŽ‰\")\n",
    "print(\"=\" * 80)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "final_answer"
   },
   "source": [
    "---\n",
    "\n",
    "# ðŸ“‹ FINAL ANSWER: Best Model and R-Squared Metric\n",
    "\n",
    "## Question: Report your final best model and corresponding R-squared metric."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "final_answer_code"
   },
   "outputs": [],
   "source": [
    "# Determine the final best model based on cross-validation\n",
    "# (Cross-validation is more reliable than single test set evaluation)\n",
    "\n",
    "print(\"\\n\" + \"=\" * 80)\n",
    "print(\"FINAL ANSWER\")\n",
    "print(\"=\" * 80)\n",
    "\n",
    "best_model_name = cv_results_df.iloc[0]['Model']\n",
    "best_cv_r2 = cv_results_df.iloc[0]['CV RÂ²']\n",
    "best_cv_rmse = cv_results_df.iloc[0]['CV RMSE']\n",
    "\n",
    "print(\"\\nðŸ† BEST MODEL (Based on 5-Fold Cross-Validation):\")\n",
    "print(\"=\" * 80)\n",
    "print(f\"\\nModel: {best_model_name}\")\n",
    "print(f\"\\nCross-Validated RÂ² Score: {best_cv_r2:.4f}\")\n",
    "print(f\"Cross-Validated RMSE: ${best_cv_rmse:,.2f}\")\n",
    "\n",
    "print(\"\\n\" + \"-\" * 80)\n",
    "print(\"WHY THIS MODEL?\")\n",
    "print(\"-\" * 80)\n",
    "\n",
    "if best_model_name == 'Model 1: Size + Rooms':\n",
    "    print(\"\\nThis model uses only two features:\")\n",
    "    print(\"  â€¢ Gr Liv Area (square footage of living area)\")\n",
    "    print(\"  â€¢ TotRms AbvGrd (total rooms above grade)\")\n",
    "    print(\"\\nStrengths:\")\n",
    "    print(\"  âœ“ Simplest model with fewest parameters\")\n",
    "    print(\"  âœ“ Less prone to overfitting\")\n",
    "    print(\"  âœ“ Best cross-validated performance\")\n",
    "    print(\"  âœ“ Most generalizable to new data\")\n",
    "elif best_model_name == 'Model 2: Size + Rooms + Bldg Type':\n",
    "    print(\"\\nThis model uses:\")\n",
    "    print(\"  â€¢ Gr Liv Area (square footage)\")\n",
    "    print(\"  â€¢ TotRms AbvGrd (total rooms)\")\n",
    "    print(\"  â€¢ Bldg Type (categorical: building type)\")\n",
    "    print(\"\\nStrengths:\")\n",
    "    print(\"  âœ“ Includes categorical building type information\")\n",
    "    print(\"  âœ“ Captures differences between dwelling types\")\n",
    "    print(\"  âœ“ Good balance of complexity and performance\")\n",
    "elif best_model_name == 'Model 3: Size Ã— Bldg Type Interaction':\n",
    "    print(\"\\nThis model uses:\")\n",
    "    print(\"  â€¢ Gr Liv Area (square footage)\")\n",
    "    print(\"  â€¢ Bldg Type (building type)\")\n",
    "    print(\"  â€¢ Interaction between Size and Building Type\")\n",
    "    print(\"\\nStrengths:\")\n",
    "    print(\"  âœ“ Captures how size affects price differently for different building types\")\n",
    "    print(\"  âœ“ More flexible than additive models\")\n",
    "    print(\"  âœ“ Can model complex relationships\")\n",
    "else:\n",
    "    print(\"\\nThis model uses:\")\n",
    "    print(\"  â€¢ 5-degree polynomial on Gr Liv Area\")\n",
    "    print(\"  â€¢ 5-degree polynomial on TotRms AbvGrd\")\n",
    "    print(\"  â€¢ Bldg Type (categorical)\")\n",
    "    print(\"\\nStrengths:\")\n",
    "    print(\"  âœ“ Can capture non-linear relationships\")\n",
    "    print(\"  âœ“ Most flexible model structure\")\n",
    "\n",
    "print(\"\\n\" + \"-\" * 80)\n",
    "print(\"INTERPRETATION OF RÂ² = {:.4f}:\".format(best_cv_r2))\n",
    "print(\"-\" * 80)\n",
    "print(f\"\\nThis model explains approximately {best_cv_r2*100:.2f}% of the variance in house prices.\")\n",
    "\n",
    "if best_cv_r2 < 0.3:\n",
    "    print(\"\\nâš  This is a relatively low RÂ² value, suggesting:\")\n",
    "    print(\"  â€¢ House prices are influenced by many factors beyond our features\")\n",
    "    print(\"  â€¢ Additional features (location, condition, age) could improve the model\")\n",
    "    print(\"  â€¢ The relationship may be inherently complex\")\n",
    "elif best_cv_r2 < 0.6:\n",
    "    print(\"\\nâœ“ This is a moderate RÂ² value, indicating:\")\n",
    "    print(\"  â€¢ The model captures important trends in house pricing\")\n",
    "    print(\"  â€¢ There is still unexplained variance that other features might capture\")\n",
    "    print(\"  â€¢ The model is useful but has room for improvement\")\n",
    "else:\n",
    "    print(\"\\nâœ“ This is a strong RÂ² value, indicating:\")\n",
    "    print(\"  â€¢ The model effectively predicts house prices\")\n",
    "    print(\"  â€¢ Our features capture most of the important pricing factors\")\n",
    "    print(\"  â€¢ The model is reliable for making predictions\")\n",
    "\n",
    "print(\"\\n\" + \"-\" * 80)\n",
    "print(\"WHY WE USE CROSS-VALIDATION:\")\n",
    "print(\"-\" * 80)\n",
    "print(\"\\nWe selected the best model based on cross-validation rather than the test set because:\")\n",
    "print(\"  1. Cross-validation averages performance over 5 different train-test splits\")\n",
    "print(\"  2. This provides a more stable and reliable estimate of model performance\")\n",
    "print(\"  3. A single test set can be 'lucky' or 'unlucky' due to randomness\")\n",
    "print(\"  4. Cross-validation better predicts how the model will perform on new data\")\n",
    "\n",
    "# Show comparison with test set if different\n",
    "if best_model_name != results_df.iloc[0]['Model']:\n",
    "    print(\"\\n\" + \"-\" * 80)\n",
    "    print(\"âš  NOTE: Test Set vs Cross-Validation Disagreement\")\n",
    "    print(\"-\" * 80)\n",
    "    print(f\"\\nThe single test set suggested: {results_df.iloc[0]['Model']}\")\n",
    "    print(f\"Cross-validation suggests: {best_model_name}\")\n",
    "    print(\"\\nThis demonstrates why cross-validation is more reliable!\")\n",
    "    print(\"The test set result may have been influenced by the particular random split.\")\n",
    "\n",
    "print(\"\\n\" + \"=\" * 80)\n",
    "print(\"END OF FINAL ANSWER\")\n",
    "print(\"=\" * 80)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "final_viz"
   },
   "source": [
    "## ðŸ“ˆ Final Visualization: Best Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "final_viz_code"
   },
   "outputs": [],
   "source": [
    "# Create a clear visualization highlighting the best model\n",
    "fig, axes = plt.subplots(1, 2, figsize=(16, 6))\n",
    "\n",
    "# Prepare data with highlighting\n",
    "models = cv_results_df['Model'].tolist()\n",
    "cv_r2_scores = cv_results_df['CV RÂ²'].tolist()\n",
    "cv_rmse_scores = cv_results_df['CV RMSE'].tolist()\n",
    "\n",
    "# Color the best model differently\n",
    "colors = ['#2ecc71' if i == 0 else '#95a5a6' for i in range(len(models))]\n",
    "\n",
    "# Plot 1: RÂ² scores\n",
    "bars1 = axes[0].barh(models, cv_r2_scores, color=colors, edgecolor='black', linewidth=2)\n",
    "axes[0].set_xlabel('Cross-Validated RÂ² Score', fontsize=13, fontweight='bold')\n",
    "axes[0].set_title('Model Performance (RÂ² Score)\\nðŸ† Best Model Highlighted in Green', \n",
    "                  fontsize=14, fontweight='bold')\n",
    "axes[0].invert_yaxis()\n",
    "\n",
    "# Add value labels\n",
    "for i, (bar, score) in enumerate(zip(bars1, cv_r2_scores)):\n",
    "    width = bar.get_width()\n",
    "    label = f'{score:.4f}'\n",
    "    if i == 0:\n",
    "        axes[0].text(width, bar.get_y() + bar.get_height()/2, \n",
    "                    f'  {label} â˜…', ha='left', va='center', \n",
    "                    fontsize=12, fontweight='bold', color='#2ecc71')\n",
    "    else:\n",
    "        axes[0].text(width, bar.get_y() + bar.get_height()/2, \n",
    "                    f'  {label}', ha='left', va='center', fontsize=11)\n",
    "\n",
    "# Plot 2: RMSE scores\n",
    "bars2 = axes[1].barh(models, cv_rmse_scores, color=colors, edgecolor='black', linewidth=2)\n",
    "axes[1].set_xlabel('Cross-Validated RMSE ($)', fontsize=13, fontweight='bold')\n",
    "axes[1].set_title('Model Performance (RMSE)\\nðŸ† Best Model Highlighted in Green', \n",
    "                  fontsize=14, fontweight='bold')\n",
    "axes[1].invert_yaxis()\n",
    "\n",
    "# Add value labels\n",
    "for i, (bar, score) in enumerate(zip(bars2, cv_rmse_scores)):\n",
    "    width = bar.get_width()\n",
    "    label = f'${score:,.0f}'\n",
    "    if i == 0:\n",
    "        axes[1].text(width, bar.get_y() + bar.get_height()/2, \n",
    "                    f'  {label} â˜…', ha='left', va='center', \n",
    "                    fontsize=12, fontweight='bold', color='#2ecc71')\n",
    "    else:\n",
    "        axes[1].text(width, bar.get_y() + bar.get_height()/2, \n",
    "                    f'  {label}', ha='left', va='center', fontsize=11)\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "print(\"\\n\" + \"=\" * 80)\n",
    "print(\"â˜… The green bars show our final best model!\")\n",
    "print(\"=\" * 80)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "model_details"
   },
   "source": [
    "## ðŸ“Š Complete Model Comparison Table"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "model_details_code"
   },
   "outputs": [],
   "source": [
    "# Create a comprehensive comparison table\n",
    "print(\"\\n\" + \"=\" * 90)\n",
    "print(\"COMPLETE MODEL COMPARISON\")\n",
    "print(\"=\" * 90)\n",
    "print(\"\\nAll Four Models Ranked by Cross-Validated Performance:\\n\")\n",
    "\n",
    "# Add rank column\n",
    "cv_results_ranked = cv_results_df.copy()\n",
    "cv_results_ranked['Rank'] = range(1, len(cv_results_ranked) + 1)\n",
    "cv_results_ranked = cv_results_ranked[['Rank', 'Model', 'CV RMSE', 'CV RÂ²']]\n",
    "\n",
    "print(cv_results_ranked.to_string(index=False))\n",
    "\n",
    "print(\"\\n\" + \"=\" * 90)\n",
    "print(f\"\\nðŸ¥‡ Winner: {cv_results_ranked.iloc[0]['Model']}\")\n",
    "print(f\"   RÂ² = {cv_results_ranked.iloc[0]['CV RÂ²']:.4f}\")\n",
    "print(\"\\n\" + \"=\" * 90)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "next_steps"
   },
   "source": [
    "---\n",
    "\n",
    "## ðŸš€ Next Steps and Exercises\n",
    "\n",
    "Now that you've completed all the practice activities, try these extensions:\n",
    "\n",
    "1. **Try different features**: Include other variables from the AMES dataset like `Year Built`, `Lot Area`, etc.\n",
    "\n",
    "2. **Experiment with different models**: Replace `LinearRegression()` with other models like Ridge, Lasso, or RandomForest\n",
    "\n",
    "3. **Expand the grid search**: Add more hyperparameters to tune:\n",
    "   ```python\n",
    "   param_grid = {\n",
    "       'preprocessing__polynomial__degree': [1, 2, 3, 4, 5],\n",
    "       'preprocessing__polynomial__interaction_only': [True, False]\n",
    "   }\n",
    "   ```\n",
    "\n",
    "4. **Visualize predictions**: Create scatter plots of actual vs predicted prices for your best model\n",
    "\n",
    "5. **Feature engineering**: Create new features like `Price per Square Foot` or `Age of House`\n",
    "\n",
    "6. **Try different CV strategies**: Use `KFold`, `StratifiedKFold`, or `TimeSeriesSplit` instead of the default 5-fold CV"
   ]
  }
 ],
 "metadata": {
  "colab": {
   "provenance": [],
   "toc_visible": true
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
